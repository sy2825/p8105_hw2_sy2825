---
title: "P8105_hw2_sy2825"
author: "Shuo Yan (sy2825)"
output: github_document
date: "2018-10-02"
---


```{r setup, include = FALSE}
library(tidyverse)
```
# Problem 1
For this problem we will focus on a NYC Transit data. First, let's input and clean the data.

```{r NYC_Transit_data}
NYC_Transit_data = 
  read.csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line:route11, entry, vending, entrance_type, ada) %>%
  mutate(
    entry = ifelse(entry == "YES", TRUE, FALSE)
  )

```
I have imported the data and used `select` function to select the data I need, I have also converted the entry variable from character to a logical variable with `ifelse` function. Now the variables in this dataset are line, station name, station latitude, station longitude, routes served, entry, vending, entrance type, and ADA compliance. And the dimension of this dataset is `r dim(NYC_Transit_data)`. These data are not tidy.

*How many distinct stations are there?

```{r distinct_stations}
nrow(
      distinct(NYC_Transit_data, station_name, line)
        )
```
So there are 465 distinct stations.




*How many stations are ADA compliant?

```{r ADA_compliant}
nrow(
      filter(NYC_Transit_data, ada == TRUE) %>%
      distinct(station_name, line)
        )
```
So there are 84 stations are ADA compliant.

*What proportion of station entrances / exits without vending allow entrance?


```{r vending_proportion} 
nrow(
      filter(NYC_Transit_data, vending == "NO") %>%
      distinct(station_name, line)
        ) / 465 
```
So the proportion is about 21.3%.       

Now let's reformat the data to make route number and route name are distinct variables.

```{r}
NYC_Transit_data_reformat = gather(NYC_Transit_data, key = "route_number", value = "route_name", route1:route11)
```
*How many distinct stations serve the A train? Of the stations that serve the A train, how many are ADA compliant?

```{r Stations_serve_A_train}
nrow(
      filter(NYC_Transit_data_reformat, route_name == "A") %>%
      distinct(station_name, line)
        )
```
So there are 60 distinct stations serve the A train.

```{r A_train_ADA_compliant}
nrow(
     filter(NYC_Transit_data_reformat, route_name == "A", ada == TRUE) %>%
      distinct(station_name, line)
)

```
So 17 of the distinct stations whcih serves the A train are ADA compliant.

# Problem 2

```{r setup_problem_2, include = FALSE}
library(readxl)
```

First let's import and clean the data.

```{r Mr.Trash_Wheel_data}
Mr.Trash_Whell_data = readxl::read_excel(
  path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
   sheet = "Mr. Trash Wheel",
  range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls = as.integer(
    round(sports_balls)
  ))

```
We have imported and cleaned the Mr. Trash Wheel data.

Now let's import and clean the precipitation data for 2016.

```{r precipitation_data_2016}
precipitation_data_2016 = readxl::read_excel(
  path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
   sheet = "2016 Precipitation", range = "A2:B14") %>%
  janitor::clean_names() %>%
   filter(!is.na(total)) %>%
 mutate(year = "2016") %>%
  rename(precipitation = total)

```


Then we import and clean the precipitation data for 2017.

```{r precipitation_data_2017}
precipitation_data_2017 = readxl::read_excel(
  path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
   sheet = "2017 Precipitation", range = "A2:B14") %>%
  janitor::clean_names() %>%
   filter(!is.na(total)) %>%
 mutate(year = "2017") %>%
  rename(precipitation = total)

```
Now let's combine the two datasets for 2016 and 2017.

```{r precipitation_data_2016_and_2017}
precipitation_data_2016_and_2017 = rbind(precipitation_data_2016, precipitation_data_2017) %>%
  select(year, month, precipitation) %>%
  arrange(month) %>%
  mutate(month = month.name[month])
                                         
```
There are `r nrow(Mr.Trash_Whell_data)` observations in the Mr. Trash Whell data. The precipitation data for 2016 contains `r nrow(precipitation_data_2016)` obervations while the precipitation data for 2017 contains `r nrow(precipitation_data_2017)`. In total the combined dataset there are `r nrow(precipitation_data_2016)` observations and the key variables are year, month, and precipitation. The total precipitation in 2017 is `r sum(precipitation_data_2017$precipitation)`. The median number of sports balls in a dumpster in 2016 is `r median(Mr.Trash_Whell_data %>% 
filter(year == "2016") %>% 
pull(sports_balls))`.

In the end let's import and clean the precipitation data for 2018.

```{r precipitation_data_2018}
precipitation_data_2018 = readxl::read_excel(
  path = "./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
   sheet = "2018 Precipitation", range = "A2:B14") %>%
  janitor::clean_names() %>%
   filter(!is.na(total)) %>%
 mutate(year = "2018") %>%
  rename(precipitation = total)

```

# Problem 3

In this problem we will focus on the BRFSS data from `p8105.datasets` package. So first let's install the package we need.
```{r install_p8105.datasets_package}
devtools::install_github("p8105/p8105.datasets")
```
Now let's import and clean the BRFSS data.

```{r BRFSS}
library(p8105.datasets)

data(brfss_smart2010)

brfss_clean = janitor::clean_names(brfss_smart2010) %>%
  rename(state = locationabbr, state_and_county = locationdesc, lower_confidence_limit = confidence_limit_low, 
         higher_confidence_limit = confidence_limit_high) %>%
  filter(topic == "Overall Health") %>%
  select(-class, -topic, -question, -sample_size, -(lower_confidence_limit:geo_location)) %>%
  spread(key = response, value = data_value) %>%
  janitor::clean_names() %>%
  mutate(excellent_or_very_good = excellent + very_good)

```
*How many unique locations are included in the dataset? Is every state represented? What state is observed the most?

Used inline code.

Answer: There are `r nrow(
  distinct(brfss_clean, state, state_and_county))` unique locations included in the dataset.

There are `r length(
  unique(brfss_clean$state))` different states (including DC) represented in the dataset which means every state is represented. 

`r names(
  which.max(
    table(brfss_clean$state)))` is observed the most.

*In 2002, what is the median of the “Excellent” response value?

```{r median_of_the_exxcellent_response_value_in_2002}
median(brfss_clean %>%
         filter(year == 2002) %>%
         pull(excellent),
       na.rm = TRUE)
```
So the median of the "Excellent" response value in 23.6.

*Make a histogram of “Excellent” response values in the year 2002.

```{r histogram_of_excellent_response_values_in_2002}
ggplot(brfss_clean %>%
         filter(year == 2002) %>%
         select(excellent), aes(x = excellent)) + geom_histogram() +
        labs(
          title = "Histogram of ''Excellent'' response values in the year 2002",
          x = "''Excellent'' response value",
          y = "Count",
          caption = "Data from BRFSS data in p8105.datasets package"
        )

```

*Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.

```{r scatterplot_excellent_response_value_in_NewYork_County_and_Queens_County_from_2002_to_2010}
ggplot(  brfss_clean %>%
         filter(state_and_county == "NY - New York County" | state_and_county == "NY - Queens County") %>%
         select(excellent, state_and_county, year), aes(x = year, y = excellent, color = state_and_county)) + geom_point() +
        labs(
          title = "''Excellent'' response values in New York County and Queens County (2002-2010)",
          x = "Year",
          y = "''Excellent'' response value",
          color = "State and County",
          caption = "Data from BRFSS data in p8105.datasets package"
        )
```



